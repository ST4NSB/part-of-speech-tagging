70% training + 30% testing:

I:
----> Text PreProcessing aplicat:

0. defaultTagger->NN:
TAG             ACCURACY                PRECISION               RECALL                  F1-SCORE
NN              0.2495743               0.2495743               1               	0.3994549
OT              0.9102265               0               	0               	0
CC              0.9432224               0               	0               	0
JJ              0.9329718               0               	0               	0
PP              0.8728252               0               	0               	0
AT/DT           0.8700157               0               	0               	0
VB              0.8396153               0               	0               	0
PN              0.9341304               0               	0               	0
RB              0.9465669               0               	0               	0
TOTAL           0.8332388               0.02773048              0.1111111               0.04438388

Accuracy for known words: 0.2058683
Accuracy for unknown words: 0.5235069
Accuracy on both: 0.2495743
~~~~~~~~~~~~~~~~~~~~

1. Cazul NULL + emission table:
TAG             ACCURACY                PRECISION               RECALL                  F1-SCORE
NN              0.9117612               0.9525443               0.6803371               0.7937518
OT              0.997542                0.9914312               0.9811          	0.9862385
CC              0.987857                0.8852243               0.9032415               0.8941422
JJ              0.9798839               0.9199278               0.7666135               0.8363021
PP              0.9887711               0.9730107               0.9377149               0.9550368
AT/DT           0.9811159               0.9830652               0.8697022               0.9229156
VB              0.9783522               0.9630053               0.8995845               0.9302151
PN              0.9835525               0.9991355               0.7509515               0.8574457
RB              0.9820117               0.8970548               0.749342                0.8165721
NULL            0.8624033               0               	0               	0
TOTAL           0.965325                0.8564399               0.7538587               0.7992619

Accuracy for known words: 0.9585137
Accuracy for unknown words: 0
Accuracy on both: 0.8266254
~~~~~~~~~~~~~~~~~~~~

2. Cazul defaultTagger->NN + emission table:
TAG             ACCURACY                PRECISION               RECALL                  F1-SCORE
NN              0.9182302               0.7656391               0.9689597               0.8553833
OT              0.997542                0.9914312               0.9811          	0.9862385
CC              0.987857                0.8852243               0.9032415               0.8941422
JJ              0.9798839               0.9199278               0.7666135               0.8363021
PP              0.9887711               0.9730107               0.9377149               0.9550368
AT/DT           0.9811159               0.9830652               0.8697022               0.9229156
VB              0.9783522               0.9630053               0.8995845               0.9302151
PN              0.9835525               0.9991355               0.7509515               0.8574457
RB              0.9820117               0.8970548               0.749342                0.8165721
TOTAL           0.9774796               0.9308326               0.8696899               0.8949168

Accuracy for known words: 0.9585137
Accuracy for unknown words: 0.5235069
Accuracy on both: 0.8986582
~~~~~~~~~~~~~~~~~~~~

3. Bigram + forward:
TAG             ACCURACY                PRECISION               RECALL                  F1-SCORE
NN              0.9744697               0.9383756               0.9608016               0.9494562
OT              0.9985601               0.9905603               0.9934276               0.9919919
CC              0.99262         	0.9095195               0.9661318               0.9369712
JJ              0.9869062               0.9295802               0.8706043               0.8991262
PP              0.9926995               0.9644203               0.9787014               0.9715084
AT/DT           0.9918282               0.9635187               0.974011                0.9687365
VB              0.9845124               0.9625263               0.9400328               0.9511467
PN              0.9975512               0.9945644               0.9681147               0.9811614
RB              0.9876583               0.9098616               0.8535874               0.8808266
TOTAL           0.989645                0.9514363               0.9450459               0.9478806

Accuracy for known words: 0.9650702
Accuracy for unknown words: 0.6811724
Accuracy on both: 0.9534028
~~~~~~~~~~~~~~~~~~~~

4. Bigram + backward:

~~~~~~~~~~~~~~~~~~~~

5. Bigram + f+b:

~~~~~~~~~~~~~~~~~~~~

6. Trigram + forward:

~~~~~~~~~~~~~~~~~~~~

7. Trigram + backward:

~~~~~~~~~~~~~~~~~~~~

8. Trigram + f+b:
{Done with training HIDDEN MARKOV MODEL & loading test files! Time: 273149 ms}
{Done with VITERBI DECODING MODEL! Time: 535022 ms}
TAG             ACCURACY                PRECISION               RECALL                  F1-SCORE
NN              0.9771997               0.9579002               0.9504141               0.9541424
OT              0.9984347               0.9907808               0.991793                0.9912866
CC              0.9936717               0.9183653               0.9752315               0.9459445
JJ              0.9869276               0.8746974               0.9395667               0.9059724
PP              0.9937756               0.9751856               0.9758888               0.9755371
AT/DT           0.9931428               0.9776107               0.9694482               0.9735124
VB              0.9853837               0.967635                0.9403187               0.9537813
PN              0.9979578               0.9817259               0.9873759               0.9845428
RB              0.9885112               0.9037194               0.8785902               0.8909777
TOTAL           0.9905561               0.9497355               0.9565141               0.9528552

Accuracy for known words: 0.9670692
Accuracy for unknown words: 0.7342855
Accuracy on both: 0.9575024
~~~~~~~~~~~~~~~~~~~~


II:
Exemplu pe Bigram forward:
1) Fara functie pt. unknown words:
Accuracy for known words: 0.9640755
Accuracy for unknown words: 0.3783382
Accuracy on both: 0.9400032

2) Cu functie dar weights calculate statistic:
Accuracy for known words: 0.9650702
Accuracy for unknown words: 0.6811724
Accuracy on both: 0.9534028