Trigram bidirectional algorithm

You chose Cross-Validation for the data-set! Folds: 4, Shuffle-option: True
Done with loading dataset & splitting them into folds!

Done with loading and creating tokens for train & test files!
Done with training HIDDEN MARKOV MODEL & calculating probabilities! Time: 122516 ms
Done with DECODING VITERBI MODEL! Time: 177679 ms
TAG             ACCURACY                PRECISION               RECALL(TPR)             F1-SCORE                SPECIFICITY(TNR)
AT/DT           0.9936323               0.9818676               0.9699612               0.9758781               0.9972571
VB              0.9868235               0.9678887               0.9490559               0.9583798               0.9940093
NN              0.9792646               0.9574499               0.959648                0.9585477               0.9857974
OT              0.9982647               0.9889512               0.9917108               0.9903291               0.9989097
JJ              0.9886581               0.9050282               0.930307                0.9174935               0.9929011
CC              0.993647                0.9206459               0.969242                0.9443191               0.9950833
PP              0.9937794               0.9755874               0.9758673               0.9757273               0.9964116
PN              0.9983309               0.9863133               0.9872333               0.9867731               0.9990779
RB              0.9886801               0.9016923               0.8843664               0.8929453               0.9945627
TOTAL           0.9912312               0.953936                0.9574879               0.9555992               0.99489


Accuracy for known words: 0.9671301
Accuracy for unknown words: 0.8000373
Accuracy on both: 0.9605403
+
Unknown words (count): 10727 | Procentage (%): 0.03943764
Known words (count): 261272 | Procentage (%): 0.9605623
Total words (count): 271999


[FOLD 1/4 DONE!]


Done with loading and creating tokens for train & test files!
Done with training HIDDEN MARKOV MODEL & calculating probabilities! Time: 129720 ms
Done with DECODING VITERBI MODEL! Time: 193383 ms
TAG             ACCURACY                PRECISION               RECALL(TPR)             F1-SCORE                SPECIFICITY(TNR)
JJ              0.9889748               0.8986033               0.9337218               0.915826                0.9927676
NN              0.9789148               0.9570198               0.9591587               0.958088                0.9855446
PN              0.998565                0.989179                0.9897651               0.989472                0.9992083
VB              0.9856973               0.9644746               0.9472797               0.9557998               0.9931926
AT/DT           0.9938341               0.9832677               0.9688943               0.976028                0.997546
PP              0.9942085               0.9758366               0.9772308               0.9765332               0.9965965
CC              0.993691                0.9199418               0.9697132               0.944172                0.9950869
OT              0.9983264               0.9921102               0.9896528               0.99088         	0.9992039
RB              0.9883142               0.8997607               0.8789713               0.8892444               0.994479
TOTAL           0.9911695               0.9533548               0.9571542               0.955116                0.9948473

Accuracy for known words: 0.9656686
Accuracy for unknown words: 0.8187351
Accuracy on both: 0.960263
+
Unknown words (count): 10024 | Procentage (%): 0.03678991
Known words (count): 262442 | Procentage (%): 0.9632101
Total words (count): 272466


[FOLD 2/4 DONE!]


Done with loading and creating tokens for train & test files!
Done with training HIDDEN MARKOV MODEL & calculating probabilities! Time: 129408 ms
Done with DECODING VITERBI MODEL! Time: 184587 ms
TAG             ACCURACY                PRECISION               RECALL(TPR)             F1-SCORE                SPECIFICITY(TNR)
AT/DT           0.9938095               0.9798568               0.9717177               0.9757702               0.9970604
NN              0.980009                0.9595579               0.9599851               0.9597715               0.9866272
PP              0.9936583               0.9747314               0.9749026               0.974817                0.9963598
OT              0.9986174               0.990806                0.9933615               0.9920821               0.9991195
JJ              0.9885076               0.8958851               0.9294063               0.912338                0.992572
CC              0.9935883               0.9177519               0.9723396               0.9442575               0.9948452
VB              0.9868042               0.968177                0.9511682               0.9595972               0.9938332
RB              0.9883011               0.9064935               0.8752203               0.8905825               0.9948063
PN              0.9984662               0.9909148               0.9874089               0.9891587               0.9993095
TOTAL           0.9913068               0.9537971               0.9572789               0.955375                0.9949481

Accuracy for known words: 0.9662654
Accuracy for unknown words: 0.827704
Accuracy on both: 0.9608808
+
Unknown words (count): 10540 | Procentage (%): 0.03886116
Known words (count): 260682 | Procentage (%): 0.9611388
Total words (count): 271222


[FOLD 3/4 DONE!]


Done with loading and creating tokens for train & test files!
Done with training HIDDEN MARKOV MODEL & calculating probabilities! Time: 119375 ms
Done with DECODING VITERBI MODEL! Time: 183228 ms
TAG             ACCURACY                PRECISION               RECALL(TPR)             F1-SCORE                SPECIFICITY(TNR)
RB              0.9892235               0.8989578               0.8869603               0.8929188               0.9946803
AT/DT           0.993908                0.9821022               0.9717922               0.9769199               0.997291
PP              0.9943328               0.9788544               0.9774616               0.9781575               0.9968498
NN              0.9795443               0.9563243               0.9635886               0.9599428               0.9849874
OT              0.9986663               0.991118                0.9933022               0.9922089               0.9991678
VB              0.9864675               0.9707212               0.9441503               0.9572514               0.9945565
JJ              0.9890757               0.9067293               0.9384755               0.9223293               0.9928326
CC              0.9940336               0.9303511               0.9667865               0.9482188               0.9956654
PN              0.998489                0.9884527               0.9867136               0.9875823               0.9992526
TOTAL           0.9915268               0.9559568               0.9588035               0.9572811               0.9950315

Accuracy for known words: 0.9676466
Accuracy for unknown words: 0.8181992
Accuracy on both: 0.9618704
+
Unknown words (count): 10462 | Procentage (%): 0.03865052
Known words (count): 260220 | Procentage (%): 0.9613495
Total words (count): 270682


[FOLD 4/4 DONE!]