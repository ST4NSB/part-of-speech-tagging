Trigram bidirectional algorithm

You chose Cross-Validation for the data-set! Folds: 4, Shuffle-option: True
Done with loading dataset & split them into folds!

Done with loading and creating tokens for train & test files!
Done with training HIDDEN MARKOV MODEL & calculating probabilities! Time: 117094 ms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Done with DECODING VITERBI MODEL! Time: 188318 ms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
TAG             ACCURACY                PRECISION               RECALL(TPR)             F1-SCORE                SPECIFICITY(TNR)
PP              0.9940695               0.9758834               0.976604                0.9762436               0.9965593
VB              0.9861522               0.9695709               0.9445614               0.9569027               0.9942373
RB              0.988806                0.9081119               0.8804781               0.8940815               0.9949484
OT              0.9985441               0.990149                0.9933417               0.9917427               0.9990462
PN              0.9985072               0.9901691               0.9871192               0.9886418               0.9993095
JJ              0.9891599               0.9091723               0.9342098               0.921521                0.9931771
CC              0.9938262               0.9233217               0.9707445               0.9464394               0.9952004
AT/DT           0.9939331               0.9813975               0.971067                0.9762049               0.9972943
NN              0.9791049               0.9545829               0.9630689               0.9588071               0.9845217
TOTAL           0.9913447               0.9558176               0.9579105               0.9567317               0.9949216

Accuracy for known words: 0.9663901
Accuracy for unknown words: 0.8234656
Accuracy on both: 0.9610515
+
Unknown words (count): 10134 | Procentage (%): 0.03735252
Known words (count): 261173 | Procentage (%): 0.9626475
Total words (count): 271307


[FOLD 1/4 DONE!]


Done with loading and creating tokens for train & test files!
Done with training HIDDEN MARKOV MODEL & calculating probabilities! Time: 121058 ms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Done with DECODING VITERBI MODEL! Time: 174418 ms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
TAG             ACCURACY                PRECISION               RECALL(TPR)             F1-SCORE                SPECIFICITY(TNR)
OT              0.9985318               0.9903116               0.9932474               0.9917774               0.9990489
CC              0.9936903               0.9204078               0.9691959               0.944172                0.9951173
PN              0.998495                0.9901654               0.9880643               0.9891137               0.9992704
VB              0.9866868               0.9685872               0.9492242               0.9588079               0.9939948
PP              0.9937967               0.9759209               0.9747828               0.9753515               0.9965356
AT/DT           0.9938591               0.9814852               0.970812                0.9761195               0.997281
NN              0.9795806               0.9575064               0.9611672               0.9593334               0.9857374
RB              0.9883606               0.8971761               0.8776888               0.8873254               0.994458
JJ              0.9889405               0.9033735               0.9303997               0.9166874               0.9930367
TOTAL           0.9913269               0.9538816               0.9571758               0.9554098               0.9949422

Accuracy for known words: 0.9665108
Accuracy for unknown words: 0.8145762
Accuracy on both: 0.9609708
+
Unknown words (count): 9934 | Procentage (%): 0.03646348
Known words (count): 262503 | Procentage (%): 0.9635365
Total words (count): 272437


[FOLD 2/4 DONE!]


Done with loading and creating tokens for train & test files!
Done with training HIDDEN MARKOV MODEL & calculating probabilities! Time: 128825 ms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Done with DECODING VITERBI MODEL! Time: 221571 ms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
TAG             ACCURACY                PRECISION               RECALL(TPR)             F1-SCORE                SPECIFICITY(TNR)
NN              0.9788979               0.9566598               0.958514                0.957586                0.9856392
JJ              0.9881529               0.8939461               0.9261603               0.9097681               0.9924261
OT              0.9983674               0.9901803               0.9914126               0.990796                0.9990438
PP              0.9936242               0.976216                0.9736211               0.9749168               0.996541
AT/DT           0.9934807               0.9807095               0.9695641               0.9751049               0.9971078
VB              0.9864835               0.9663123               0.9501231               0.9581493               0.9935566
PN              0.9984961               0.9896098               0.9873239               0.9884655               0.9992762
RB              0.9881087               0.898976                0.8811721               0.889985                0.9942828
CC              0.9936499               0.9225643               0.9693983               0.9454016               0.9951079
TOTAL           0.991029                0.9527971               0.9563655               0.9544637               0.9947757

Accuracy for known words: 0.9659337
Accuracy for unknown words: 0.8080148
Accuracy on both: 0.9596307
+
Unknown words (count): 10855 | Procentage (%): 0.03991337
Known words (count): 261109 | Procentage (%): 0.9600866
Total words (count): 271964


[FOLD 3/4 DONE!]


Done with loading and creating tokens for train & test files!
Done with training HIDDEN MARKOV MODEL & calculating probabilities! Time: 157839 ms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Done with DECODING VITERBI MODEL! Time: 244179 ms
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
TAG             ACCURACY                PRECISION               RECALL(TPR)             F1-SCORE                SPECIFICITY(TNR)
NN              0.9792249               0.9563026               0.961583                0.9589356               0.9851767
VB              0.9867768               0.9688507               0.9475501               0.958082                0.9942197
RB              0.9892855               0.9037516               0.8856753               0.8946221               0.9948941
PP              0.9941883               0.9762149               0.978867                0.9775392               0.9964615
JJ              0.9886648               0.9067838               0.9273394               0.9169465               0.9931022
CC              0.9937966               0.9217502               0.9694974               0.9450211               0.9952106
AT/DT           0.9938521               0.9830508               0.9709251               0.9769503               0.9974055
OT              0.9984002               0.9915038               0.9903846               0.9909439               0.9991773
PN              0.9983411               0.9854783               0.9880924               0.9867836               0.9990264
TOTAL           0.9913924               0.954854                0.9577683               0.9562027               0.9949638

Accuracy for known words: 0.9677784
Accuracy for unknown words: 0.8036678
Accuracy on both: 0.9612652
+
Unknown words (count): 10742 | Procentage (%): 0.03968802
Known words (count): 259919 | Procentage (%): 0.9603119
Total words (count): 270661


[FOLD 4/4 DONE!]